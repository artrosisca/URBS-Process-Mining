{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41728bc6-13b7-44d0-89f5-598c1340290c",
   "metadata": {},
   "source": [
    "# TCC - Mineração de Processos no Transporte Público de Curitiba\n",
    "\n",
    "## Etapa 1: Aquisição e Estruturação de Dados da API URBS\n",
    "\n",
    "O primeiro passo fundamental deste projeto é a coleta de dados brutos do sistema de transporte. Com base na documentação oficial fornecida, vamos interagir com o web service da URBS para obter a posição dos veículos.\n",
    "\n",
    "O método específico para esta tarefa é o `getVeiculos.php`. A autenticação é realizada passando um código de acesso como um parâmetro (`c`) diretamente na URL da requisição.\n",
    "\n",
    "Utilizaremos a biblioteca `requests` para fazer a chamada HTTP e a biblioteca `pandas` para estruturar a resposta JSON em um DataFrame, que é a estrutura de dados ideal para as próximas etapas de análise.\n",
    "\n",
    "### Boas Práticas e Recomendações da URBS\n",
    "É fundamental seguir as diretrizes da URBS para evitar o bloqueio do acesso:\n",
    "- **Frequência de Atualização:** Os dados de localização são atualizados a cada 2 minutos. Portanto, fazer requisições em uma frequência maior que essa é desnecessário e pode ser interpretado como uso abusivo.\n",
    "- **Evitar Excesso de Requisições:** Múltiplas requisições em um curto período de tempo serão tratadas como um ataque de negação de serviço (DoS), resultando no bloqueio imediato do acesso. Para este TCC, faremos chamadas pontuais para coletar os dados necessários para a análise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77201915-6a19-493f-a9d0-74dd3bdfd223",
   "metadata": {},
   "source": [
    "### Importe de bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2edc87a-3d2c-4423-8c55-f2ed5a742c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12a5ba26-029e-45ae-a66d-6c1535cbcb1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acessando a API em: https://transporteservico.urbs.curitiba.pr.gov.br/getVeiculos.php\n",
      "Com os parâmetros: {'c': '65d35'}\n",
      "\n",
      "Conexão e recebimento de dados bem-sucedidos!\n",
      "\n",
      "Dados brutos carregados com sucesso em um DataFrame:\n",
      "                JI009       JI004      HI035       HE715       GE726  \\\n",
      "COD             JI009       JI004      HI035       HE715       GE726   \n",
      "REFRESH         18:20       18:20      18:23       18:22       18:19   \n",
      "LAT          -25.5119  -25.467826   -25.4594  -25.464513  -25.434023   \n",
      "LON          -49.3244  -49.355215  -49.35881  -49.255631  -49.269328   \n",
      "CODIGOLINHA       826         826        826         550         550   \n",
      "\n",
      "                  HE720       GE729       GE713       GI033       GI031  ...  \\\n",
      "COD               HE720       GE729       GE713       GI033       GI031  ...   \n",
      "REFRESH           18:23       18:22       18:20       18:23       18:23  ...   \n",
      "LAT          -25.468951  -25.511711  -25.549625  -25.543006  -25.543645  ...   \n",
      "LON          -49.253646  -49.291555  -49.291748  -49.262486  -49.261358  ...   \n",
      "CODIGOLINHA         550         550         REC         541         541  ...   \n",
      "\n",
      "                  HI029       BI888       EA005       EI002       EI014  \\\n",
      "COD               HI029       BI888       EA005       EI002       EI014   \n",
      "REFRESH           18:16       18:21       18:23       18:20       18:21   \n",
      "LAT          -25.554301  -25.391763  -25.506505  -25.502868   -25.51665   \n",
      "LON          -49.305893  -49.260878  -49.245161  -49.225886  -49.230833   \n",
      "CODIGOLINHA         646         266         522         515         533   \n",
      "\n",
      "                  BI891       PI005       ML314       MN605       BI873  \n",
      "COD               BI891       PI005       ML314       MN605       BI873  \n",
      "REFRESH           18:22       18:23       18:22       18:22       18:12  \n",
      "LAT          -25.376906  -25.448828  -25.426645   -25.39747  -25.363535  \n",
      "LON           -49.26266  -49.201918  -49.285546  -49.350345  -49.233568  \n",
      "CODIGOLINHA         244         323         X46         948         236  \n",
      "\n",
      "[5 rows x 1475 columns]\n"
     ]
    }
   ],
   "source": [
    "# --- Configurações para a API da URBS ---\n",
    "# URL base do web service\n",
    "base_url = \"https://transporteservico.urbs.curitiba.pr.gov.br/\"\n",
    "\n",
    "# Endpoint específico para obter a posição dos veículos\n",
    "endpoint = \"getVeiculos.php\"\n",
    "\n",
    "# Seu código de acesso pessoal fornecido pela URBS\n",
    "api_code = \"65d35\"\n",
    "\n",
    "# Construindo a URL completa\n",
    "full_url = f\"{base_url}{endpoint}\"\n",
    "\n",
    "# Parâmetros da requisição. A biblioteca 'requests' adicionará isso à URL \n",
    "params = {\n",
    "    'c': api_code\n",
    "}\n",
    "# -----------------------------------------\n",
    "\n",
    "print(f\"Acessando a API em: {full_url}\")\n",
    "print(f\"Com os parâmetros: {params}\")\n",
    "\n",
    "try:\n",
    "    # Realiza a requisição GET para a API, passando os parâmetros\n",
    "    response = requests.get(full_url, params=params, timeout=30)\n",
    "    \n",
    "    # Lança uma exceção se a resposta indicar um erro de HTTP (ex: 401, 403, 500)\n",
    "    response.raise_for_status()   \n",
    "    \n",
    "    # Converte a resposta JSON em um dicionário/lista Python\n",
    "    data = response.json()\n",
    "    print(\"\\nConexão e recebimento de dados bem-sucedidos!\")\n",
    "\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"\\nERRO: Falha ao acessar a API. Causa: {e}\")\n",
    "    data = None\n",
    "except requests.exceptions.JSONDecodeError:\n",
    "    print(\"\\nERRO: A resposta recebida não está no formato JSON.\")\n",
    "    print(\"Isso pode acontecer se o acesso for negado ou a página retornou um erro HTML.\")\n",
    "    print(\"Conteúdo da resposta recebida:\")\n",
    "    print(response.text)\n",
    "    data = None\n",
    "\n",
    "# Verifica se os dados foram recebidos e os carrega em um DataFrame\n",
    "if data:\n",
    "    try:\n",
    "        # A API deve retornar uma lista de dicionários, um para cada veículo.\n",
    "        # Podemos converter isso diretamente para um DataFrame.\n",
    "        df_raw = pd.DataFrame(data)\n",
    "\n",
    "        print(\"\\nDados brutos carregados com sucesso em um DataFrame:\")\n",
    "        # Exibe as 5 primeiras linhas do DataFrame para verificação\n",
    "        print(df_raw.head())\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\nERRO: Falha ao converter os dados recebidos para um DataFrame. Causa: {e}\")\n",
    "        print(\"Estrutura de dados recebida para análise:\")\n",
    "        print(data)\n",
    "else:\n",
    "    print(\"\\nNenhum dado foi carregado. Verifique a mensagem de erro acima.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6aa8f12-23a4-4975-964f-8e5ac02d1592",
   "metadata": {},
   "source": [
    "### Aplicando _transpose_ para melhor visualização da tabela"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9541cd0f-ce76-4f73-8f70-c06e43aaef59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_raw = pd.read_csv('./DataFrames/DF_inicial.csv', index_col=0)\n",
    "#df_transposed = df_raw.T\n",
    "#df_transposed.to_csv('./DataFrames/DF_transposed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30aabac6-57a6-4ebd-bb00-be628ed56b58",
   "metadata": {},
   "source": [
    "## Etapa 2: Preparação e Limpeza dos Dados\n",
    "\n",
    "Com os dados brutos carregados no DataFrame `df_raw`, a próxima etapa é a limpeza e padronização. Este passo é crucial para transformar os dados em um formato utilizável para as fases subsequentes de análise.\n",
    "\n",
    "As principais tarefas nesta etapa são:\n",
    "1.  **Renomear as colunas:** Alterar os nomes originais da API (ex: `COD`, `LAT`, `CODIGOLINHA`) para um padrão mais claro e consistente (ex: `vehicle_id`, `latitude`, `line_id`), conforme sugerido pelo guia metodológico.\n",
    "2.  **Converter e criar o Timestamp:** A coluna `REFRESH` da API contém apenas o horário. Para criar um timestamp completo, que é uma coluna obrigatória para a mineração de processos, vamos combinar este horário com a data atual. Em seguida, converteremos esta nova coluna para o tipo de dados `datetime` do pandas, o que permite ordenação cronológica e cálculos de tempo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6042e1ce-f07f-4e8e-bbbb-0ece3432c601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Colunas após renomear ---\n",
      "Index(['JI009', 'JI004', 'HI035', 'HE715', 'GE726', 'HE720', 'GE729', 'GE713',\n",
      "       'GI033', 'GI031',\n",
      "       ...\n",
      "       'HI029', 'BI888', 'EA005', 'EI002', 'EI014', 'BI891', 'PI005', 'ML314',\n",
      "       'MN605', 'BI873'],\n",
      "      dtype='object', length=1475)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'refresh_time'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'refresh_time'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 33\u001b[39m\n\u001b[32m     30\u001b[39m today_date_str = \u001b[38;5;28mstr\u001b[39m(pd.to_datetime(\u001b[33m'\u001b[39m\u001b[33mtoday\u001b[39m\u001b[33m'\u001b[39m).date())\n\u001b[32m     32\u001b[39m \u001b[38;5;66;03m# Cria uma nova coluna 'timestamp' combinando a data de hoje com a hora da coluna 'refresh_time'\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m df_cleaned[\u001b[33m'\u001b[39m\u001b[33mtimestamp\u001b[39m\u001b[33m'\u001b[39m] = pd.to_datetime(today_date_str + \u001b[33m'\u001b[39m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m + \u001b[43mdf_cleaned\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrefresh_time\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m, \n\u001b[32m     34\u001b[39m                                          \u001b[38;5;28mformat\u001b[39m=\u001b[33m'\u001b[39m\u001b[33m%\u001b[39m\u001b[33mY-\u001b[39m\u001b[33m%\u001b[39m\u001b[33mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m%\u001b[39m\u001b[33mH:\u001b[39m\u001b[33m%\u001b[39m\u001b[33mM\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     36\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m--- Verificação dos tipos de dados (note a coluna \u001b[39m\u001b[33m'\u001b[39m\u001b[33mtimestamp\u001b[39m\u001b[33m'\u001b[39m\u001b[33m) ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     37\u001b[39m df_cleaned.info()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/frame.py:4107\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4105\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4106\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4107\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4108\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4109\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/indexes/base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'refresh_time'"
     ]
    }
   ],
   "source": [
    "# Supondo que 'df_raw' é o DataFrame criado no Passo 1\n",
    "# Se você reiniciou o notebook, carregue os dados do CSV salvo:\n",
    "# df_raw = pd.read_csv('./DataFrames/DF_inicial.csv', index_col=0)\n",
    "\n",
    "# 1. Renomeando as colunas para um padrão mais claro\n",
    "# Mapeamento do nome original para o novo nome\n",
    "column_mapping = {\n",
    "    'COD': 'vehicle_id',\n",
    "    'REFRESH': 'refresh_time',\n",
    "    'LAT': 'latitude',\n",
    "    'LON': 'longitude',\n",
    "    'CODIGOLINHA': 'line_id',\n",
    "    'ADAPT': 'adapted_vehicle',\n",
    "    'TIPO_VEIC': 'vehicle_type',\n",
    "    'TABELA': 'schedule_table',\n",
    "    'SITUACAO': 'situation',\n",
    "    'SITUACAO2': 'situation_2',\n",
    "    'SENT': 'direction',\n",
    "    'TCOUNT': 't_count' # Mantendo t_count para referência\n",
    "}\n",
    "\n",
    "df_cleaned = df_raw.rename(columns=column_mapping)\n",
    "\n",
    "print(\"--- Colunas após renomear ---\")\n",
    "print(df_cleaned.columns)\n",
    "\n",
    "\n",
    "# 2. Tratando e criando a coluna de Timestamp\n",
    "# Como a API retorna apenas a hora, vamos combinar com a data de hoje.\n",
    "today_date_str = str(pd.to_datetime('today').date())\n",
    "\n",
    "# Cria uma nova coluna 'timestamp' combinando a data de hoje com a hora da coluna 'refresh_time'\n",
    "df_cleaned['timestamp'] = pd.to_datetime(today_date_str + ' ' + df_cleaned['refresh_time'], \n",
    "                                         format='%Y-%m-%d %H:%M')\n",
    "\n",
    "print(\"\\n--- Verificação dos tipos de dados (note a coluna 'timestamp') ---\")\n",
    "df_cleaned.info()\n",
    "\n",
    "print(\"\\n--- Visualização do DataFrame limpo ---\")\n",
    "print(df_cleaned.head())\n",
    "\n",
    "# Opcional: Salvar este DataFrame limpo para uso futuro\n",
    "# df_cleaned.to_csv('./DataFrames/DF_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f488d26a-541b-46a2-a456-e7073a69a3c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
